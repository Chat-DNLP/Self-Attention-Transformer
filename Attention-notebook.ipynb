{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica: implementación del mecanismo de auto-atención con enmascaramiento del modelo Transformer\n",
    "\n",
    "Vamos a implementar el mecanismo de auto-atención con enmascaramiento del modelo Transformer en Pytorch. Para ello, vamos a seguir los pasos descritos anteriormente y suponer que ya tenemos las matrices de consultas (Q), claves (K) y valores (V) para cada token en la secuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Cálculo de las puntuaciones de atención\n",
    "Matrices de consultas (Q), claves (K) y valores (V):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.tensor([[0.0, 0.0, 0.0], [1, 1, 1], [0.2, 0.2, 0.2], [0.3, 0.3, 0.3]])\n",
    "K = torch.tensor([[0.1, 0.1, 0.1], [0.2, 0.2, 0.2], [0.3, 0.3, 0.3], [0.4, 0.4, 0.4]])\n",
    "V = torch.tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.], [0., 1., 1.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El enmascaramiento durante la etapa del decodificador en los modelos Transformer es crucial para evitar que el decodificador tenga acceso a información futura, especialmente en tareas de generación secuencial como la traducción automática o la generación de texto. Este concepto se conoce como \"enmascaramiento de atención causal\".\n",
    "\n",
    "En el contexto de los Transformers, el decodificador genera una salida secuencialmente, palabra por palabra. Durante la generación de cada palabra, es importante que el modelo solo tenga en cuenta las palabras anteriores y no las futuras, ya que estas últimas no deberían estar disponibles (en un escenario de generación de texto, por ejemplo, las palabras futuras aún no se han generado).\n",
    "\n",
    "Una vez realizado el resultado debe ser:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td><b>z1</b></td><td>1.0000</td><td>0.0000</td><td>0.0000</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>z2</b></td><td>0.4568</td><td>0.5432</td><td>0.0000</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>z3</b></td><td>0.3219</td><td>0.3332</td><td>0.3449</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>z4</b></td><td>0.2309</td><td>0.5130</td><td>0.5260</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "#### **Objetivos de la práctica**\n",
    "\n",
    "- Entender con detalle el funcionamiento del mecanismo de auto-atención con enmascaramiento.\n",
    "- Practicar las operaciones matriciales en PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Escalado de las puntuaciones de atención\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3000, 0.6000, 0.9000, 1.2000],\n",
      "        [0.0600, 0.1200, 0.1800, 0.2400],\n",
      "        [0.0900, 0.1800, 0.2700, 0.3600]])\n"
     ]
    }
   ],
   "source": [
    "Kt = K.t()\n",
    "QKt = torch.matmul(Q, Kt)\n",
    "print(QKt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Paso 3: Aplicación de la matriz de enmascaramiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3000, 0.6000, 0.0000, 0.0000],\n",
      "        [0.0600, 0.1200, 0.1800, 0.0000],\n",
      "        [0.0900, 0.1800, 0.2700, 0.3600]])\n"
     ]
    }
   ],
   "source": [
    "masked_matrix = torch.tril(QKt)\n",
    "print(masked_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Dividir las puntuaciones de atención por la raíz cuadrada de la dimensión de las consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "tensor([[  -inf,   -inf,   -inf,   -inf],\n",
      "        [0.1732, 0.3464,   -inf,   -inf],\n",
      "        [0.0346, 0.0693, 0.1039,   -inf],\n",
      "        [0.0520, 0.1039, 0.1559, 0.2078]])\n"
     ]
    }
   ],
   "source": [
    "#d_k = Kt.size()\n",
    "#importar inf\n",
    "inf = float('-inf')\n",
    "print(d_k)\n",
    "scaled_scores = masked_matrix / math.sqrt(3)\n",
    "scored_inf = scaled_scores.masked_fill(masked_matrix == 0, float('-inf'))\n",
    "print(scored_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1732, 0.3464, 0.0000, 0.0000],\n",
      "        [0.0346, 0.0693, 0.1039, 0.0000],\n",
      "        [0.0520, 0.1039, 0.1559, 0.2078]])\n"
     ]
    }
   ],
   "source": [
    "print(scaled_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5: Aplicación de la función Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
      "        [0.2583, 0.3072, 0.2172, 0.2172],\n",
      "        [0.2455, 0.2542, 0.2631, 0.2372],\n",
      "        [0.2309, 0.2432, 0.2561, 0.2698]])\n"
     ]
    }
   ],
   "source": [
    "attention = torch.nn.functional.softmax(scaled_scores, dim=1)\n",
    "print(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
      "        [0.2575, 0.2992, 0.2216, 0.2216],\n",
      "        [0.2461, 0.2536, 0.2614, 0.2389],\n",
      "        [0.2334, 0.2441, 0.2554, 0.2671]])\n"
     ]
    }
   ],
   "source": [
    "print(attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 6: Multiplicación con la matriz de valores (V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.5000, 0.5000],\n",
      "        [0.2575, 0.5208, 0.4433],\n",
      "        [0.2461, 0.4925, 0.5002],\n",
      "        [0.2334, 0.5112, 0.5225]])\n"
     ]
    }
   ],
   "source": [
    "attention_vectors = torch.matmul(attention, V)\n",
    "print(attention_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 0.2000, 0.3000, 0.4000],\n",
      "        [0.1000, 0.2000, 0.3000, 0.4000],\n",
      "        [0.1000, 0.2000, 0.3000, 0.4000]])\n"
     ]
    }
   ],
   "source": [
    "print(Kt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import scaled_dot_product_attention\n",
    "z = scaled_dot_product_attention(Q, K, V, is_causal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.4568, 0.5432, 0.0000],\n",
      "        [0.3219, 0.3332, 0.3449],\n",
      "        [0.2309, 0.5130, 0.5260]])\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
